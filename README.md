# Classical-Chinese-Translation

## 📚 Table of Contents

- [Overview](#overview)
- [Installation](#installation)
- [Usage](#usage)
- [Inference](#inference)
- [Acknowledgements](#acknowledgements)
- [License](#license)
- [Contact](#contact)

## 🌟 Overview
The Classical-Chinese-Translation project aims to fine-tune transformer models for bidirectional translation between Classical Chinese and modern languages. Utilizing advanced techniques like LoRA (Low-Rank Adaptation) and PEFT (Parameter-Efficient Fine-Tuning), the project optimizes translation performance with minimal computational resources. This work enables seamless translation between ancient texts and modern languages, bridging cultural and historical knowledge gaps..

## 💻 Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/Shengwei-Peng/Classical-Chinese-Translation.git
    ```
2. Navigate to the project directory:
    ```sh
    cd Classical-Chinese-Translation
    ```
3. Install the required dependencies:
    ```sh
    pip install -r requirements.txt
    ```

## ⚙️ Usage

## 🔮 Inference

## 🙏 Acknowledgements

This project is based on the example code provided by Hugging Face in their [Transformers repository](https://github.com/huggingface/transformers/tree/main/examples/pytorch). We have made modifications to adapt the code for our specific use case.

Special thanks to the [NTU Miulab](http://adl.miulab.tw) professors and teaching assistants for providing the dataset and offering invaluable support throughout the project.

## ⚖️ License

This project is licensed under the Apache License 2.0. See the [LICENSE](./LICENSE) file for more details.

## ✉️ Contact

For any questions or inquiries, please contact m11207330@mail.ntust.edu.tw